@Proceedings{IWSSL-22,
    booktitle = {Proceedings of The 3rd International Workshop on Self-Supervised Learning},
    name = {International Workshop on Self-Supervised Learning},
    shortname = {IWSSL},
    editor = {Th{\'o}risson, Kristinn R.},
    volume = {192},
    year = {2022},
    start = {2022-7-28},
    end = {2022-7-29},
    published = {2022-04-03},
    conference_url = {http://cadia.ru.is/events/IWSSL22/},
    address = {Reykjavik University, Reykjavik, Iceland}
}

@InProceedings{thorisson22a,
  title={IWSSL: Introduction to this volume},
  author={Th{\'o}risson, Kristinn R.},
  pages={1--4},
  abstract = {}
}

@InProceedings{thorisson22b,
  title={The Future of {AI} Research:~{T}en Defeasible ‘Axioms of Intelligence’},
  author={Th{\'o}risson, Kristinn R. and Minsky, Henry},
  pages={5--21},
  abstract = {What sets artificial intelligence (AI) apart from other fields of science and technology is~\textit{\textbf{not}} what it has achieved so far, but rather what it set out to do from the very beginning, namely, \textit{to create autonomous self-contained systems that can rival human cognition}---machines with `human-level general intelligence.'~To achieve this aim calls for a new \textit{kind} of system that, among other things, unifies -- in a single architecture -- the ability to represent causal relations, create and manage knowledge incrementally and autonomously, and generate its own meaning through empirical reasoning and control.~We maintain that building such systems requires a shared methodological foundation, and calls for a stronger theoretical basis than simply the one inherited directly from computer science.~This, in turn, calls for a greater emphasis on the theory of intelligence and methodological approaches for building such systems.~We argue that necessary (but not necessarily sufficient) components for general intelligence must include the unification of causal relations, reasoning, and cognitive development.~A constructivist stance, in our view, can serve as a good starting point for this purpose.}
}


@InProceedings{zhou22,
  title={Novel Primitive Decompositions for Real-World Physical Reasoning},
  author={Zhou, Mackie and Duah, Bridget and Macbeth, Jamie C.},
  pages={22--34},
  abstract = {In this work, we are concerned with developing cognitive representations that may enhance the ability for self-supervised learning systems to learn language as part of their world explorations.~We apply insights from in-depth language understanding systems to the problem, specifically representations which decompose language inputs into language-free structures that are complex combinations of primitives representing cognitive abstractions such as object permanence, movement, and spatial relationships.~These decompositions, performed by a system traditionally called a \textit{conceptual analyzer}, link words with complex non-linguistic structures that engender the rich relations between language expressions and world exploration that are a familiar aspect of intelligence. We focus on improving and extending both the Conceptual Dependency (CD) representation system, its primitive decompositions, and its conceptual analyzer, choosing as our corpus the ProPara (``Process Paragraphs'') dataset, which consists of paragraphs describing biological, chemical, and physical processes of the kind that appear in grade-school science textbooks (e.g., photosynthesis, erosion).~In doing so, we avoid the significant challenges of decomposing concepts involving communication, thought, and complex social interactions.~To meet the challenges of this dataset, we contribute a \textit{mental motion pictures} representation system with  important innovations, such as using image schemas in place of CD primitives and decoupling containment relationships into separate primitives.}
}

@InProceedings{wang22,
  title={Intelligence:~{F}rom Definition to Design},
  author={Pei Wang},
  pages={35--47},
  abstract = {This paper provides a non-technical description of the ideas behind a model of intelligence that has been formalized and computerized.~These ideas are organized into a train of thought consisting of the major design decisions of the model and contrasted with the major approaches in the field of artificial intelligence.~The implications of these decisions are also discussed.}
}

@InProceedings{sheikhlar22,
  title={Explicit General Analogy for Autonomous Transversal Learning},
  author={Sheikhlar, Arash and Th{\'o}risson, Kristinn R.  and Thompson, Jeff},
  pages={48--62},
  abstract = {Making analogies is a kind of reasoning where two or more things are compared, to highlight or uncover attributes of interest.~Besides being useful for comparing what is known, analogy making can help a learning agent deal with tasks and environments not experienced before, where similarities and differences to known phenomena and their cause-effects relations can be a source for generating hypotheses about novel phenomena, which in turn can serve as a basis for exploration and experimentation.~Artificial intelligence (AI) systems that can make use of explicit analogies are relatively rare, and those making general analogies are even rarer. This may be because most AI systems are targeted to well-known tasks, relying heavily on human programmers for knowledge creation, an approach that -- besides being intractably slow, error-prone, and highly ineffective -- precludes the use of analogies for enabling autonomous knowledge transfer between tasks, domains, and environments with common characteristics.~The automation of explicit analogy making in the service of such knowledge transfer has, in our view, at least three prerequisites:~(a) Compositional knowledge representation, (b) reasoning machinery, and (c) the ability of the agent to make experiments on its surroundings.~For an agent's intelligence to be general, the methods chosen for these must be domain-independent and available on-demand at the agent's discretion.~The agent would identify a target novelty, generate hypotheses about what the novelty is `like' through analogies, generate a set of hypotheses with potential to disqualify these and select between competing hypotheses, and intervene on the environment through direct action to test them.~Here we describe the design of an analogy mechanism that allows a learning agent with the above features to autonomously, using previously-learned causal knowledge, make analogies between a source and target task, hypothesize sets of new causal models for performing the new tasks, and to verify the validity of these through a set of autonomously generated actions.~We describe how this general approach can be implemented in an existing cognitive system, the Autocatlytic Endogenous Reflective Architecture {(AERA)}.}
}

@InProceedings{komrusch22a,
  title={Symbolic Guidance for Constructivist Learning by Neural Model},
  author={Komrusch, Steve and Minsky, Henry},
  pages={63--76},
  abstract = {Deep learning has made impressive strides but still lacks key concepts necessary to truly reason and act in the world.~In parallel, symbolic learning systems have shown success at certain types of abstract reasoning, as demonstrated in the Abstraction and Reasoning Challenge by Kaggle.~Yet, these symbolic learners are challenged when generalizing to data from the analog world.~This paper will present and evaluate ideas for using symbolic learning concepts to guide learning of a neural network in a constructivist way.~We aim to show how a neural network with internal feedback can be used - somewhat like the brain - to suggest the proper actions to take and predict the results of those actions.~In other words, the system will create an internal model of the world on which it can reason.~The neurosymbolic system we consider is inspired by the symbolic learning system from Gary Dresher and neural network cortical columns as discussed by Jeff Hawkins.~The hybrid system aims to create a synthesis which can generalize on real-world concepts while also quickly learning from few examples as the world changes and prior experience is found to be inaccurate.}
}

@InProceedings{georgeon22,
  title={Simultaneous Localization and Active Phenomenon Inference {(SLAPI)}},
  author={Georgeon, Olivier and Vidal, Juan R. and Knockaert, Titouan and Robertson, Paul},
  pages={77--88},
  abstract = {We introduce the problem for a robot to  localize itself, and, simultaneously, actively infer the existence and properties of \textit{phenomena} present in its surrounding environment:~the SLAPI problem.~A phenomenon is a representation of an entity ``as the robot experiences it'' through interaction.~The SLAPI problem relates to the SLAM (simultaneous localization and mapping) problem but differs in that it does not aim at constructing a precise map of the environment, and it can apply to robots with coarse sensors.~We demonstrate a SLAPI algorithm to control a robot equipped with omni-directional wheels, an echo-localization sensor, photosensitive sensors, and an inertial measurement unit, but no precise sensors like camera, lidar, or odometry.~As the robot circles around an object, it constructs the phenomenon corresponding to this object under the form of the set of the spatially-localized control loops of interaction that the object affords to the robot.~SLAPI algorithms could help design companion robots that mimic intrinsic motivation such as curiosity and playfulness.~Further studies of the SLAPI problem could improve the scientific understanding of how cognitive beings construct knowledge about objects from sensorimotor experience of interaction.}
}

@InProceedings{hammer22,
  title={Reasoning-Learning Systems Based on {Non-Axiomatic Reasoning System} Theory},
  author={Hammer, Patrick},
  pages={89--107},
  abstract = {In this paper a strong motivation for real-time reasoning-learning systems based on Non-Axiomatic Reasoning System (NARS) Theory as an approach to build intelligent systems with agency is given.~This contains the requirement to work under the Assumption of Insufficient Knowledge and Resources which demands open-ended adaptation while obeying to strict computational resource restrictions to allow for real-time response.~We show how this aligns with the phenomenon of intelligence as found in nature, allowing for systems which can both react instantly, and plan ahead deliberately dependent on implicitly outcome-dependent time pressures.~In this context a specific implementation design is considered, OpenNARS for Applications (ONA), and how its learning and reasoning abilities lead to data-efficient adaptation in novel circumstances in various domains, whereby we compare with a reinforcement learning method, Q-Learning, in Space Invaders, Pong and a grid robot environment. We will see that both techniques perform comparably well for reactive tasks in Markovian environments, while the uncertainty reasoner performs better when the Markov property is violated, with the additional property that it can plan ahead to exploit task compositionality, also taking explicit background knowledge into account.}
}

@InProceedings{komrusch22b,
  title={Neurosymbolic Learning on Activity Summarization of Video Data},
  author={Komrusch, Steve and Bhave, Sanket and Banik, Mridul and Minsky, Henry},
  pages={108--119},
  abstract = {Neurosymbolic learning systems have been shown to quickly discover how to interact with discrete representations of the world.~Symbolic learners often allow for a higher level of understandability than neural networks which learn feature vectors for actions being taken, as seen in modern reinforcement learning systems.~Symbolic learners excel at learning higher-level concepts, but struggle with certain types of generalization.~Symbolic learners might benefit in such situations from a learned representation of the world.~This paper discusses a pipeline that uses state-of-the-art object and pose detection neural networks as input to a symbolic learning system.~We show how the knowledge from the symbolic system can automatically correct object and pose data from the neural network and hence provide corrected samples that can be used to incrementally train and improve the neural network.~We show how symbolic learning techniques can improve action detection when given example ground truths by humans.~We also demonstrate how novel actions that are not recognized by humans might be recognized by a learning engine capable of recognizing results and preconditions for an action to be valid.}
}

@InProceedings{steunebrink22,
  title={The {H}olon System: Artificial General Intelligence as ‘Work on Command’},
  author={Steunebrink, Bas and Swan, Jerry and Nivel, Eric},
  pages={120--126},
  abstract = {Recent interest in the `Large Language Models' of deep learning has led to widespread conjecture that artificial general intelligence (AGI) is thereby imminent.~At the other end of the spectrum, it has also been claimed that `general' intelligence cannot exist at all.~In this extended abstract, we argue that both of these perspectives are misconceived.~We provide a pragmatic definition of general intelligence, grounded in fundamental business and engineering requirements.~We explain why a `deployed regression model' (such as deep learning) cannot meet this criterion for \emph{generality} of intelligence.~We then proceed to describe the \ARC system, designed and implemented to meet this criterion.}
}

@InProceedings{latapie22,
  title={Hybrid {AI} for {IoT} Actionable Insights \& Real-Time Data-Driven Networks},
  author={Latapie, Hugo and Gabriel, Mina and Kompella, Ramana},
  pages={127--131},
  abstract = {Significant increases in industry requirements for network bandwidth are seen year upon year.~The exponential growth in streaming data is matched by an increase in the use of machine learning and deep learning to glean actionable -- ideally real-time -- insights from these data.~However, approaches based on artificial neural networks (ANNs) are often insufficient in terms of functionality, flexibility, accuracy, explainability, and robustness.~The demand for new model development and continual updating and retraining is outstripping the model generation capacity of data scientists and others in the field.~This gap between supply and demand for real-time data driven insights continues to grow.~In this paper we introduce a hybrid AI solution which adds several elements into the ML/DL mix, specifically a new self-supervised learning mechanism, a knowledge model engineered to include support for machine generated ontologies as well as traditional human-generated ontologies, and interfaces to symbolic AI systems such as OpenNARS, AERA, ONA, and OpenCog, among other elements.~Our hybrid AI system enables self-supervised learning of machine-generated ontologies from millions of time series, to provide real-time data-driven insights for large-scale deployments including data centers and enterprise networks.~We also apply the same hybrid AI to video analytics use cases. Our preliminary results across all the use cases we have attempted to-date are promising although more work is needed to fully characterize both the benefits and limitations of our approach. }
}
 